{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : loss = 33.906, /t accuracy =0.557/0.801\n",
      "Epoch 2 : loss = 8.225, /t accuracy =0.820/0.755\n",
      "Epoch 3 : loss = 7.582, /t accuracy =0.812/0.865\n",
      "Epoch 4 : loss = 7.476, /t accuracy =0.808/0.785\n",
      "Epoch 5 : loss = 7.397, /t accuracy =0.810/0.820\n",
      "Epoch 6 : loss = 7.331, /t accuracy =0.808/0.779\n",
      "Epoch 7 : loss = 7.272, /t accuracy =0.808/0.810\n",
      "Epoch 8 : loss = 7.220, /t accuracy =0.808/0.838\n",
      "Epoch 9 : loss = 7.178, /t accuracy =0.810/0.838\n",
      "Epoch 10 : loss = 7.138, /t accuracy =0.809/0.860\n",
      "\n",
      "filnal Test : final accuracy = 0.860\n",
      "[[1.03338961]\n",
      " [1.47724746]\n",
      " [1.67992711]\n",
      " [2.03717282]\n",
      " [1.60645146]\n",
      " [0.62703825]\n",
      " [2.42585997]\n",
      " [0.52521222]\n",
      " [0.46959183]\n",
      " [0.96029006]] [4.16916919]\n",
      "Epoch 5 : loss = 6.807, /t accuracy =0.809/0.808\n",
      "Epoch 10 : loss = 6.474, /t accuracy =0.813/0.794\n",
      "Epoch 15 : loss = 6.237, /t accuracy =0.818/0.818\n",
      "Epoch 20 : loss = 6.018, /t accuracy =0.821/0.811\n",
      "Epoch 25 : loss = 5.843, /t accuracy =0.824/0.805\n",
      "Epoch 30 : loss = 5.696, /t accuracy =0.826/0.811\n",
      "Epoch 35 : loss = 5.548, /t accuracy =0.828/0.833\n",
      "Epoch 40 : loss = 5.451, /t accuracy =0.831/0.818\n",
      "Epoch 45 : loss = 5.374, /t accuracy =0.832/0.833\n",
      "Epoch 50 : loss = 5.273, /t accuracy =0.834/0.835\n",
      "Epoch 55 : loss = 5.219, /t accuracy =0.834/0.833\n",
      "Epoch 60 : loss = 5.182, /t accuracy =0.834/0.842\n",
      "Epoch 65 : loss = 5.127, /t accuracy =0.836/0.833\n",
      "Epoch 70 : loss = 5.097, /t accuracy =0.836/0.844\n",
      "Epoch 75 : loss = 5.075, /t accuracy =0.836/0.840\n",
      "Epoch 80 : loss = 5.031, /t accuracy =0.837/0.820\n",
      "Epoch 85 : loss = 5.016, /t accuracy =0.838/0.829\n",
      "Epoch 90 : loss = 5.006, /t accuracy =0.838/0.823\n",
      "Epoch 95 : loss = 4.981, /t accuracy =0.837/0.805\n",
      "Epoch 100 : loss = 4.958, /t accuracy =0.839/0.818\n",
      "\n",
      "filnal Test : final accuracy = 0.818\n"
     ]
    }
   ],
   "source": [
    "# 코드 재활용을 위한 아발로니 파일 실행\n",
    "%run Single_Layer_Percept_전복고리수.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인함수 정의\n",
    "def steel_exec(epoch_count=10,mb_size=10,report=1):\n",
    "    load_steel_dataset()\n",
    "    init_model()\n",
    "    train_test(epoch_count,mb_size,report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 적재함수 정의\n",
    "def load_steel_dataset():\n",
    "    with open(\"faults.csv\") as csvfile:\n",
    "        csvreader=csv.reader(csvfile)\n",
    "        next(csvreader,None)\n",
    "        rows=[]\n",
    "\n",
    "        for row in csvreader:\n",
    "            for i in range(0,len(row)) :\n",
    "                if row[i]=='':row[i]=0\n",
    "            rows.append(row)\n",
    "\n",
    "    global data, input_cnt, output_cnt\n",
    "    input_cnt, output_cnt = 27,7\n",
    "    data = np.asarray(rows,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  후처리 과정에 대한 순전파와 역전파 함수 재정의\n",
    "def forward_postproc(output,y):\n",
    "    entropy = softmax_cross_entropy_with_logits(y,output)\n",
    "    loss=np.mean(entropy)\n",
    "    return loss,[y,output,entropy]\n",
    "\n",
    "def backprop_postproc(G_loss,aux):\n",
    "    y,output,entropy=aux\n",
    "    \n",
    "    g_loss_entropy=1.0/np.prod(entropy.shape)\n",
    "    g_entropy_output=softmax_cross_entropy_with_logits_derv(y,output)\n",
    "    \n",
    "    G_entropy = g_loss_entropy * G_loss\n",
    "    G_output = g_entropy_output * G_entropy\n",
    "    \n",
    "    return G_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 함수 재정의\n",
    "# 신경망이 추정한 선택값과 정답으로 주어진 선택값이 같은 결과인지 조사하여 올바른 추정 비율 구하기\n",
    "def eval_accuracy(output,y):\n",
    "    estimate = np.argmax(output,axis=1) # 후보항목에 관한 각 로짓값을 담고 있는 벡터에서 가장 큰 값이 어디에 있는지 조사\n",
    "    answer=np.argmax(y,axis=1)\n",
    "    correct = np.equal(estimate,answer)\n",
    "    \n",
    "    return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 함수 정의\n",
    "def softmax(x):\n",
    "    max_elem=np.max(x,axis=1) # 행렬의 각 행에서 최대항을 골라냄, \n",
    "    diff= (x.transpose() - max_elem).transpose() # 행렬 전치하여 계산 후 다시 원상복귀처리 \n",
    "    exp=np.exp(diff)\n",
    "    sum_exp=np.sum(exp,axis=1)\n",
    "    probs=(exp.transpose()/sum_exp).transpose()\n",
    "    \n",
    "    return probs\n",
    "\n",
    "# 소프트맥스 함수의 편미분 : 미니배치 데이터에 대한 야코비안 행렬 구하기\n",
    "def softmax_derv(x,y):\n",
    "    mb_size, nom_size=x.shape\n",
    "    derv=np.ndarray([mb_size,nom_size,nom_size])\n",
    "    for n in range(mb_size):\n",
    "        for i in range(nom_size):\n",
    "            for j in range(nom_size):\n",
    "                derv[n,i,j] = -y[n,i]*y[n,j]\n",
    "            derv[n,i,i] += y[n,i]\n",
    "    \n",
    "    return derv\n",
    "\n",
    "def softmax_cross_entropy_with_logits(labels,logits):\n",
    "    probs = softmax(logits)\n",
    "    \n",
    "    return  -np.sum(labels*np.log(probs+1.0e-10),axis=1)\n",
    "\n",
    "def softmax_cross_entropy_with_logits_derv(labels,logits):\n",
    "    return softmax(logits) - labels\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : loss = 15.910, /t accuracy =0.309/0.300\n",
      "Epoch 2 : loss = 15.925, /t accuracy =0.308/0.600\n",
      "Epoch 3 : loss = 15.628, /t accuracy =0.321/0.400\n",
      "Epoch 4 : loss = 15.539, /t accuracy =0.325/0.300\n",
      "Epoch 5 : loss = 15.509, /t accuracy =0.326/0.300\n",
      "Epoch 6 : loss = 15.806, /t accuracy =0.314/0.600\n",
      "Epoch 7 : loss = 15.494, /t accuracy =0.327/0.200\n",
      "Epoch 8 : loss = 15.554, /t accuracy =0.325/0.400\n",
      "Epoch 9 : loss = 15.435, /t accuracy =0.330/0.400\n",
      "Epoch 10 : loss = 15.227, /t accuracy =0.339/0.600\n",
      "\n",
      "filnal Test : final accuracy = 0.600\n"
     ]
    }
   ],
   "source": [
    "steel_exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
