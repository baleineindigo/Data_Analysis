{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1624177220.9945195\n"
     ]
    }
   ],
   "source": [
    "# 난수 생성\n",
    "np.random.seed(1234)\n",
    "def randomize():\n",
    "    np.random.seed(int(time.time()))\n",
    "#     print(time.time())\n",
    "\n",
    "# Hyper-parameter\n",
    "# : 가중치 파라미터 초기화\n",
    "rnd_mean = 0\n",
    "rnd_std =0.03\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "# : abalone_exec 함수를 호출하여 1) 데이터셋 로드 > 2) 파라미터 초기화 > 3) 학습 및 평가 수행\n",
    "# 즉, 딥러닝 모델 생성부터 학습 과정 전체를 abalone_exec 함수로 일괄 처리\n",
    "\n",
    "def abalone_exec(epoch_cnt=10 , mb_size = 10, report =1):\n",
    "    # 1) 데이터셋 로드\n",
    "    load_abalone_dataset()\n",
    "    # 2) 파라미터 초기화\n",
    "    init_model()\n",
    "    # 3) Training & Test\n",
    "    train_n_test(epoch_cnt,mb_size,report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) DATA LOAD\n",
    "def load_abalone_dataset():\n",
    "    with open (\"abalone.csv\") as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader,None) # 첫행 건너뛰기. 헤더 무시\n",
    "        rows=[]\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "    \n",
    "    global data, input_cnt, output_cnt\n",
    "    input_cnt, output_cnt = 10,1  # 전복 개체들의 입출력 벡터 크기를 10과 1로 지정\n",
    "    data = np.zeros([len(abalone),input_cnt+ output_cnt])\n",
    "\n",
    "    for n,row in enumerate(abalone):\n",
    "        if row[0]=='I' : data [n,0] =1   # 비선형인 성별 정보를 one-hot 벡터 표현으로 변환\n",
    "        if row[0]=='M' : data [n,1] =1\n",
    "        if row[0]=='F' : data [n,2] =1            \n",
    "        data [n,3:] =row[1:]  # 성별 이외의 정보를 일괄 복제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_model 함수 정의 : 파라미터 초기화\n",
    "def init_model():\n",
    "    global weight, bias, input_cnt,output_cnt\n",
    "    weight =np.random.normal(rnd_mean,rnd_std,[input_cnt,output_cnt])\n",
    "    bias=np.zeros([output_cnt])\n",
    "    print(weight,bias)\n",
    "\n",
    "init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test set\n",
    "def train_test(epoch_count,mb_size,report):\n",
    "    step_count=arrange_data(mb_size)  # 데이터 셔플, train & test 셋 분리, 정렬 작업 수행\n",
    "    test_x,test_y=get_test_data()     \n",
    "    \n",
    "    for epoch in range(epoch_count):  # 인수로 지정된 에포크 수만큼 학습 반복\n",
    "        losses,accs = [],[]\n",
    "        \n",
    "        for n in range(step_count):  # step_count 값만큼 미니배치 처리 반복\n",
    "            train_x,train_y =get_test_data(mb_size,n)  \n",
    "            losses,accs = run_train(train_x,train_y)   # train 데이터 가져와 학습\n",
    "            losses.append(loss)     # 미니배치에서 손실과 정확도 값을 각각 적재\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if report > 0 and (epoch+1)  % report ==0:  # report : 보고주기. 보고주기에 맞으면 손실 및 정확도를 출력\n",
    "            acc=run_test(train_x,train_y )\n",
    "            print('Epoch {} : loss = {:5.3f}, /t accuracy ={:5.3f}/{:5.3f}'.format(epoch+1,np.mean(losses),np.mean(accs),acc))\n",
    "    \n",
    "    final_acc =run_test(train_x,train_y )  # 최종 테스트 함수 호출 및 값 출력\n",
    "    print('\\nfilnal Test : final accuracy = {:5.3f}'.format(final_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test 에서 사용한 함수 정의\n",
    "\n",
    "def arrange_data(mb_size):    # 데이터 수만큼 일련번호 발생 후 shuffle\n",
    "    global data , shuffle_map, test_begin_idx  \n",
    "    shuffle_map=np.arrange(data.shape[0])\n",
    "    np.random.shuffle(shuffle_map)\n",
    "    step_count=int(data.shape[0]*0.8)//mb_size\n",
    "    test_begin_idx=step_count*mb_size  # train 과 test를 구분하는 경계 인덱스\n",
    "    \n",
    "    return step_count\n",
    "\n",
    "\n",
    "def get_test_data():   \n",
    "    global data , shuffle_map, test_begin_idx,output_cnt\n",
    "    test_data=data[shuffle_map[test_begin_idx:]]\n",
    "    \n",
    "    return test_data[:,:-output_cnt],test_data[:,-output_cnt:]\n",
    "    \n",
    "    \n",
    "\n",
    "def get_train_data(mb_size,nth):\n",
    "    global data , shuffle_map, test_begin_idx\n",
    "    if nth==0:  # nth가 0이면 train set을 부분적으로 섞어 에포크마다 다른 순서로 학습\n",
    "        np.random.shuffle(shuffle_map[:test_begin_idx])\n",
    "    trian_data=data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\n",
    "\n",
    "    return trian_data[:,:-output_cnt],trian_data[:,-output_cnt:]\n",
    "\n",
    "\n",
    "# 학습실행 함수와 평가 실행 함수\n",
    "def run_train(x,y):\n",
    "    output,aux_nn = forward_neuralnet(x)\n",
    "    loss, aux_pp =forward_postproc(x)\n",
    "    accuracy = eval_accuracy(output,y)\n",
    "    \n",
    "    G_loss =1.0\n",
    "    G_output = backprop_postproc(G_loss,aux_pp)\n",
    "    backprop_neuralnet(G_loss,aux_nn)\n",
    "    \n",
    "    return loss,accuracy\n",
    "\n",
    "\n",
    "def run_test(x,y):\n",
    "    output,_ =forward_neuralnet(x)\n",
    "    accuracy=eval_accuracy(output,y)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
