{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "군집화.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "UVge3AwJyGHu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJepEkqewJZn"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poKzWoFH0KL3"
      },
      "source": [
        "from sklearn.datasets import *\r\n",
        "from sklearn.cluster import *\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.utils.testing import ignore_warnings\r\n",
        "\r\n",
        "np.random.seed(0)\r\n",
        "n_samples = 1500\r\n",
        "blobs = make_blobs(n_samples=n_samples, random_state=8)\r\n",
        "X, y = make_blobs(n_samples=n_samples, random_state=170)\r\n",
        "anisotropic = (np.dot(X, [[0.6, -0.6], [-0.4, 0.8]]), y)\r\n",
        "varied = make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=170)\r\n",
        "noisy_circles = make_circles(n_samples=n_samples, factor=.5, noise=.05)\r\n",
        "noisy_moons = make_moons(n_samples=n_samples, noise=.05)\r\n",
        "no_structure = np.random.rand(n_samples, 2), None\r\n",
        "datasets = {\r\n",
        "    \"같은 크기의 원형\": blobs, \r\n",
        "    \"같은 크기의 타원형\": anisotropic, \r\n",
        "    \"다른 크기의 원형\": varied, \r\n",
        "    \"초승달\": noisy_moons, \r\n",
        "    \"동심원\": noisy_circles, \r\n",
        "    \"비구조화\": no_structure\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "plt.figure(figsize=(11, 11))\r\n",
        "plot_num = 1\r\n",
        "for i, (data_name, (X, y)) in enumerate(datasets.items()):\r\n",
        "    if data_name in [\"초승달\", \"동심원\"]:\r\n",
        "        n_clusters = 2\r\n",
        "    else:\r\n",
        "        n_clusters = 3\r\n",
        "\r\n",
        "    X = StandardScaler().fit_transform(X)\r\n",
        "\r\n",
        "    two_means = MiniBatchKMeans(n_clusters=n_clusters)\r\n",
        "    dbscan = DBSCAN(eps=0.15)\r\n",
        "    spectral = SpectralClustering(n_clusters=n_clusters, affinity=\"nearest_neighbors\")\r\n",
        "    ward = AgglomerativeClustering(n_clusters=n_clusters)\r\n",
        "    affinity_propagation = AffinityPropagation(damping=0.9, preference=-200)\r\n",
        "    clustering_algorithms = (\r\n",
        "        ('K-Means', two_means),\r\n",
        "        ('DBSCAN', dbscan),\r\n",
        "        ('Hierarchical Clustering', ward),\r\n",
        "        ('Affinity Propagation', affinity_propagation),\r\n",
        "        ('Spectral Clustering', spectral),\r\n",
        "    )\r\n",
        "\r\n",
        "    for j, (name, algorithm) in enumerate(clustering_algorithms):\r\n",
        "        with ignore_warnings(category=UserWarning):\r\n",
        "            algorithm.fit(X)\r\n",
        "        if hasattr(algorithm, 'labels_'):\r\n",
        "            y_pred = algorithm.labels_.astype(np.int)\r\n",
        "        else:\r\n",
        "            y_pred = algorithm.predict(X)\r\n",
        "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\r\n",
        "        if i == 0:\r\n",
        "            plt.title(name)\r\n",
        "        if j == 0:\r\n",
        "            plt.ylabel(data_name)\r\n",
        "        colors = plt.cm.tab10(np.arange(20, dtype=int))\r\n",
        "        plt.scatter(X[:, 0], X[:, 1], s=5, color=colors[y_pred])\r\n",
        "        plt.xlim(-2.5, 2.5)\r\n",
        "        plt.ylim(-2.5, 2.5)\r\n",
        "        plt.xticks(())\r\n",
        "        plt.yticks(())\r\n",
        "        plot_num += 1\r\n",
        "\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rjLqN510Xsu"
      },
      "source": [
        "import numpy as np\r\n",
        "# A = np.arange(2*3*4).reshape((2,3,4))\r\n",
        "# B = np.arange(2*3*4).reshape((2,4,3))\r\n",
        "\r\n",
        "np.dot(A,B)\r\n",
        "# (2, 3, 2, 3)\r\n",
        "# np.matmul(A,B).shape\r\n",
        "# (2, 3, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSOOso2Vq6Ma"
      },
      "source": [
        "## 군집화\r\n",
        ": 주어진 데이터 집합을 유사한 데이터들의 그룹으로 나누는 방법론으로,\r\n",
        "예측문제와 딜리 특정한 독립/종속 변수의 구분도 럾고 학습을 위한 목푯값도 필요없는 비지도 학습이다.\r\n",
        "\r\n",
        "[방법]\r\n",
        "- K평균 군집화\r\n",
        "- 디비스캔 군집화\r\n",
        "- 유사도 전파 군집화\r\n",
        "- 계층적 군집화\r\n",
        "- 스펙트럴 군집화 \r\n",
        "\r\n",
        "군집화 방법은 사용법과 모수가 서로 다르다.\r\n",
        "K평균이나 스펙트럴 군집화는 군집의 개수를 미리 지정해야 한다. 반면, 디비스캔과 유사도 전파법은 미리 정할 필요가 없지만, 모형에 따라 특별한 모수를 지정해주어야 하는데 모수 값에 따라 군집화 개수가 달라질 수 있다.\r\n",
        "\r\n",
        "각 군집화 방법마다 특성이 다르므로 원하는 목적과 데이터 유형에 맞게 사용해야 한다. 또한 지정된 모수의 값에 따라 성능이 달라질 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoHP_0pZsjUH"
      },
      "source": [
        "#### 군집화 성능기준¶\r\n",
        "군집화의 경우에는 분류문제와 달리 성능기준을 만들기 어렵다. 심지어는 원래 데이터가 어떻게 군집화되어 있었는지를 보여주는 정답(groundtruth)이 있는 경우도 마찬가지이다. 따라서 다양한 성능기준이 사용되고 있다. 다음의 군집화 성능기준의 예다.\r\n",
        "\r\n",
        "\\\r\n",
        "*★일치행렬 : N개 데이터 집합에서 i,j 2개의 데이터를 선택했을 때, 두 데이터가 같은 군집에 속하면 1, 다른 군집에 속하면 0이라 하자. 이 값을 N*N 행렬 T로 나타낼 수 있다.\r\n",
        "\r\n",
        "    T=1 (군집i=군집j)\r\n",
        "    =0 (군집i!=군집j)\r\n",
        "\r\n",
        "\\\r\n",
        "\r\n",
        "\r\n",
        "1) 조정 랜드지수(Adjusted Rand Index)\r\n",
        "\r\n",
        "\r\n",
        "2) 조정 상호정보량 (Adjusted Mutual Information)\r\n",
        "\r\n",
        "3) 실루엣계수 (Silhouette Coefficient)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg3KXwfQu66p"
      },
      "source": [
        "###### 일치 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJgzvhxPp9tD"
      },
      "source": [
        "'''\r\n",
        "ex)예를 들어 {0,1,2,3,4}라는 5개의 데이터 집합에서 \r\n",
        "{0,1,2}와 {3,4}가 각각 같은 군집라면 행렬 T는 다음과 같다.\r\n",
        "'''\r\n",
        "groundtruth   = np.array([\r\n",
        "[1, 1, 1, 0, 0],\r\n",
        "[1, 1, 1, 0, 0],\r\n",
        "[1, 1, 1, 0, 0],\r\n",
        "[0, 0, 0, 1, 1],\r\n",
        "[0, 0, 0, 1, 1],])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4JClEMavP-S"
      },
      "source": [
        "'''\r\n",
        "이제 군집화 결과를 같은 방법으로 행렬 C로 표시하자. \r\n",
        "만약 군집화이 정확하다면 이 행렬은 정답을 이용해서 만든 행렬과 거의 같은 값을 가져야 한다.\r\n",
        "만약 군집화 결과 {0,1}과 {2,3,4}가 같은 군집라면 행렬 C는 다음과 같다.\r\n",
        "'''\r\n",
        "clustering = np.array([\r\n",
        "    [1, 1, 0, 0, 0],\r\n",
        "    [1, 1, 0, 0, 0],\r\n",
        "    [0, 0, 1, 1, 1],\r\n",
        "    [0, 0, 1, 1, 1],\r\n",
        "    [0, 0, 1, 1, 1],\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRcDjZQUvP6X"
      },
      "source": [
        "'''\r\n",
        "이 두 행렬의 모든 원소에 대해 값이 같으면 1 다르면 0으로 \r\n",
        "계산한 행렬을 일치행렬(incidence matrix)이라고 한다. \r\n",
        "즉 데이터 집합에서 만들수 있는 모든 데이터 쌍에 대해 \r\n",
        "정답과 군집화 결과에서 동일한 값을 나타내면 1, 다르면 0이 된다.\r\n",
        "R=1 (Tij=Cij)\r\n",
        " =0 (Tij!=Cij)\r\n",
        "\r\n",
        "즉, 원래 정답에서 1번 데이터와 2번 데이터가 같은(다른) 군집인데 \r\n",
        "군집화 결과에서도 같은(다른) 군집이라고 하면 R12=1이다.\r\n",
        "위 예제에서 일치행렬을 구하면 다음과 같다.\r\n",
        "'''\r\n",
        "incidence=1*(groundtruth==clustering)\r\n",
        "incidence\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1d7M-euvP3c"
      },
      "source": [
        "'''\r\n",
        "이 일치 행렬은 두 데이터의 순서를 포함하므로 대칭행렬이다. \r\n",
        "만약 데이터의 순서를 무시한다면 위 행렬에서 대각성분과 \r\n",
        "아래쪽 비대각 성분은 제외한 위쪽 비대각 성분만을 고려해야 한다. \r\n",
        "위쪽 비대각 성분에서 1의 개수는 다음과 같아진다.\r\n",
        "\r\n",
        "a=T에서 같은 군집에 있고 C에서도 같은 군집에 있는 데이터 쌍의 수 \r\n",
        "b=T에서 다른 군집에 있고 C에서도 다른 군집에 있는 데이터 쌍의 수\r\n",
        "일치행렬 위쪽 비대각 성분에서 1의 개수=a+b\r\n",
        "'''\r\n",
        "np.fill_diagonal(incidence,0)  # 대각성분 제외\r\n",
        "a_plus_b=np.sum(incidence)/2  # 대칭행렬의 절반만 계산\r\n",
        "a_plus_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVge3AwJyGHu"
      },
      "source": [
        "###### 랜드지수\r\n",
        "가능한 모든 데이터 쌍의 개수에 대해 정답인 데이터 쌍의 개수의 비율로 정의\r\n",
        "Rand INdex=(a+b)/nC2\r\n",
        "\r\n",
        "###### 조정 랜드지수\r\n",
        "랜드지수는 0부터 1까지의 값을 가지고 1이 가장 좋은 성능을 뜻한다. 랜드지수의 문제점은 무작위로 군집화을 한 경우에도 어느 정도 좋은 값이 나올 가능성이 높다는 점이다. 즉 무작위 군집화에서 생기는 랜드지수의 기댓값이 너무 크다. \r\n",
        "\r\n",
        "이를 해결하기 위해 무작위 군집화에서 생기는 랜드지수의 기댓값을 원래의 값에서 빼서 기댓값과 분산을 재조정한 것이 조정 랜드지수(adjusted Rand index, ARI)다.\r\n",
        "\r\n",
        "ARI=(RI-E[RI])/(max(RI)-E[RI])\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_g_YQszvP1D"
      },
      "source": [
        "from scipy.special import comb\r\n",
        "rand_index=a_plus_b/comb(incidence.shape[0],2) \r\n",
        "#incidence행렬 : 5X5 >> incidence.shape[0]=5\r\n",
        "rand_index\r\n",
        "'''\r\n",
        "adjusted Rand index는 성능이 완벽한 경우 1이 된다. \r\n",
        "반대로 가장 나쁜 경우로서 무작위 군집화을 하면 0에 가까운 값이 나온다.\r\n",
        "경우에 따라서는 음수가 나올 수도 있다.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-iPIUkevPx-"
      },
      "source": [
        "'''\r\n",
        "여러가지 군집화 방법을 적용하였을때 조정 랜드지수를 계산해보면\r\n",
        "디비스캔과 스펙트럴 군집화의 값이 높게 나오는 것을 확인할 수 있다. \r\n",
        "scikit-learn 패키지의 metrics.cluster 서브패키지는 조정 랜드지수를 계산하는 adjusted_rand_score 명령을 제공한다.\r\n",
        "'''\r\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\r\n",
        "\r\n",
        "X,Y_true=anisotropic\r\n",
        "X,Y_true\r\n",
        "plot_num=1\r\n",
        "X=StandardScaler().fit_transform(X)\r\n",
        "for name,algorithm in clustering_algorithms:\r\n",
        "    with ignore_warnings(category=UserWarning):\r\n",
        "        algorithm.fit(X)\r\n",
        "    if hasattr(algorithm,'labels_'):\r\n",
        "        Y_pred=algorithm.labels_.astype(np.int)\r\n",
        "    else:\r\n",
        "        Y_pred=algorithm.predict(X)\r\n",
        "    title=\"ARI={:5.3f}\".format(adjusted_rand_score(Y_true,Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dVqmOegzIGY"
      },
      "source": [
        "# hasattr?\r\n",
        "# Return whether the object has an attribute with the given name."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvdz4WwF9j4d"
      },
      "source": [
        "###### 상호 정보량\r\n",
        "두 확률 변수 간의 상호 의존성을 측정한 값.\r\n",
        "군집화 결과를 이산확률변수로 가정\r\n",
        "정답은 T={T1,T2,...,Tr}의 r개의 값을 가지는 이산확률변수이고\r\n",
        "군집화 결과는 C={C1,C2,...,Cs}의 s개의 값을 가질 수 있는 이산확률변수라고 하자.\r\n",
        "\r\n",
        "전체 데이터의 개수를 N이라고 하면 이산확률변수 T의 분포는\r\n",
        "P(i)=|Ti|/N 로 추정할 수 있다. 이 식에서 |Ti|는 군집 Ti에 속하는 데이터의 개수를 나타낸다.\r\n",
        "\r\n",
        "비슷하게 이산확률변수 C의 분포는\r\n",
        "P'(j)=|Cj|/N 으로 추정하고 T와 C의 결합확률분포는 P(i,j)=|Ti∩Cj|/N로 추정한다. 여기서 |Ti∩Cj|는 군집 Ti에도 속하고 군집 Cj에도 속하는 데이터의 개수를 나타낸다.\r\n",
        "\r\n",
        "확률변수 T,C의 상호 정보량은 MI(T,C)=∑i=1∑j=1(P(i,j)*{log(P(i,j)/P(i)P(j))}으로 정의한다.\r\n",
        "\r\n",
        "만약 두 확률변수가 서로 독립이면 상호정보량의 값은 0이면 이 값이 상호정보량이 가질 수 있는 최소값이다. 두 확률변수가 의존성이 강할 수록 상호정보량이 증가한다. 또한 군집의 개수가 많아져도 상호정보량이 증가하므로 올바른 비교가 어렵다. 따라서 상호정보량의 기댓값을 빼서 재조정한 것이 조정 상호 정보량이다.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JgVGE9M8u3l"
      },
      "source": [
        "# 상호정보량 & 조정상호정보량\r\n",
        "from sklearn.metrics.cluster import adjusted_mutual_info_score\r\n",
        "\r\n",
        "plt.figure(figsize=(12,2))\r\n",
        "plot_num=1\r\n",
        "for name,algorithm in clustering_algorithms:\r\n",
        "    with ignore_warnings(category=UserWarning):\r\n",
        "        algorithm.fit(X)\r\n",
        "    if hasattr(algorithm,'labels_'):\r\n",
        "        Y_pred=algorithm.labels_.astype(np.int)\r\n",
        "    else:\r\n",
        "        Y_pred=algorithm.predict(X)\r\n",
        "    title=\"ARI={:5.3f}\".format(adjusted_mutual_info_score(Y_true,Y_pred))\r\n",
        "    \r\n",
        "    plt.subplot(1,len(datasets),plot_num)\r\n",
        "    plt.scatter(X[:,0],X[:,1],s=5,color=colors[y_pred])\r\n",
        "    plt.xlim(-2.5,2.5)\r\n",
        "    plt.ylim(-2.5,2.5)\r\n",
        "    plt.xticks(())\r\n",
        "    plt.yticks(())\r\n",
        "    plt.title(title)\r\n",
        "    plot_num+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTxzmFLTF63A"
      },
      "source": [
        "###### 3) 실루엣 계수\r\n",
        "원래 데이터가 속한 군집을 모를 경우 군집화 성능을 평가하는 지수.\r\n",
        "\r\n",
        "모든 데이터 쌍(i,j)에 대해 거리/비윳도를 구한 다음, 이 결과를 이용하여 모든 데이터 i에 대해 다음 값을 구한다.\r\n",
        "- ai : i와 같은 군집에 속한 원소들의 평균 거리\r\n",
        "- bi : i와 다른 군집 중 가장 가까운 군집까지의 평균 거리\r\n",
        "\r\n",
        "si=(bi−ai)/max(ai,bi)로 정의하고, 전체 데이터의 실루엣 계수의 평균된 값을 평균 실루엣계수라고 한다.\r\n",
        "\r\n",
        "- 데이터 i에 대해 같은 군집의 데이터가 다른 군집의 데이터보다 더 가까운 경우 : 해당 데이터 (+)\r\n",
        "- 다른 군집의 데이터가 같은 군집의 데이터보다 더 가깝다면 : 해당 데이터의 실루엣계수 (-) >>> 군집화이 잘못된 경우\r\n",
        "\r\n",
        "잘못된 군집화에서는 실루엣계수가 음수인 데이터가 많아지므로 평균 실루엣계수가 작아진다. 따라서 실루엣계수가 클수록 좋은 군집화이라고 할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt3QClR_B-D1"
      },
      "source": [
        "# 실루엣 계수\r\n",
        "from sklearn.metrics import silhouette_samples\r\n",
        "\r\n",
        "def plot_silhouette(data):\r\n",
        "    X=StandardScaler().fit_transform(data[0])\r\n",
        "    colors=plt.cm.tab10(np.arange(20,dtype=int))\r\n",
        "    plt.figure(figsize=(6,8))\r\n",
        "    for i in range(4):\r\n",
        "        model=SpectralClustering(n_clusters=i+2,affinity=\"nearest_neighbors\")\r\n",
        "        cluster_labels=model.fit_predict(X)\r\n",
        "        sample_silhouette_values=silhouette_samples(X,cluster_labels)\r\n",
        "        silhouette_avg=sample_silhouette_values.mean()\r\n",
        "\r\n",
        "        plt.subplot(4,2,2*i+1)\r\n",
        "        Y_lower=10\r\n",
        "        for j in range(i+2):\r\n",
        "            jth_cluster_sillhouette_values=sample_silhouette_values[cluster_labels==j]\r\n",
        "            jth_cluster_sillhouette_values.sort()\r\n",
        "            size_cluster_j=jth_cluster_sillhouette_values.shape[0]\r\n",
        "            Y_upper=Y_lower+size_cluster_j\r\n",
        "            plt.fill_betweenx(np.arange(Y_lower,Y_upper),\r\n",
        "                              0,jth_cluster_sillhouette_values,\r\n",
        "                              facecolor=colors[j],edgecolor=colors[j])\r\n",
        "            plt.text(-0.05, Y_lower + 0.5 * size_cluster_j, str(j + 1))\r\n",
        "            plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\r\n",
        "            plt.xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\r\n",
        "            plt.yticks([])\r\n",
        "            plt.title(\"Sillhouette Average: {:5.2f}\".format(silhouette_avg))\r\n",
        "            Y_lower = Y_upper + 10\r\n",
        "\r\n",
        "        plt.subplot(4, 2, 2 * i + 2)\r\n",
        "        plt.scatter(X[:, 0], X[:, 1], s=5, color=colors[cluster_labels])\r\n",
        "        plt.xlim(-2.5, 2.5)\r\n",
        "        plt.ylim(-2.5, 2.5)\r\n",
        "        plt.xticks(())\r\n",
        "        plt.yticks(())\r\n",
        "        plt.title(\"Num. of Clusters : {}\".format(i + 2))\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "plot_silhouette(blobs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fROCA7KtY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}